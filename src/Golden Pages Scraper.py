# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bjst4U5uh5GM7YPjSUdAQHXhziVu4G23
"""

from urllib.request import urlopen
from urllib.error import HTTPError
from bs4 import BeautifulSoup
import re

def clean_text(text):
  #text = text.strip().replace("\n", " ")
  text = " ".join(text.split())
  return text

def getCompanyName(bs):
  try:
    name = bs.h1.get_text()
  except AttributeError as e:
    return ""
  return clean_text(name)

def getCompanyMainPhone(bs):
  try:
    CompMainPhone = bs.find('', {'class': 'mainphone'}).get_text()
  except AttributeError as e:
    return ""
  return clean_text(CompMainPhone)

def getCompanyPhone(bs):
  try:
    CompPhone = bs.find('div', {'itemprop': 'telephone'}).get_text()
  except AttributeError as e:
    return ""
  return clean_text(CompPhone)

def getAddress(bs):
  try:
    address = bs.find('li', {'itemprop': 'address'}).get_text()
  except AttributeError as e:
    address = bs.find('', {'class': 'address'})
    if address != None:
      address = address.get_text()
    else:
      return ""
  return clean_text(address)

def getEmail(bs):
  try:
    email = bs.find('', {'data-link': 'email'}).get_text()
  except AttributeError as e:
    return ""
  return clean_text(email)

def getWebsite(bs):
  try:
    website = bs.find('a', {'rel': 'nofollow'}).get_text()
  except AttributeError as e:
    return ""
  return clean_text(website)

def getFax(bs):
  try:
    fax = bs.find('', {'id': 'faxinfo'}).get_text().split(':')[-1]
  except AttributeError as e:
    return ""
  return clean_text(fax)

def getAbout(bs):
  try:
    about = bs.find('', {'class': 'about'}).parent.get_text()
  except AttributeError as e:
    return ""
  return clean_text(about)

def getCategories(bs):
  categories = []
  try:
    category = bs.find('span', {'class': 'cat_type'}).get_text()
    categories.append(category)
  except AttributeError as e:
    pass
  
  try:
    catList = bs.find('', {'id': 'catList'})
    for cat in catList.findChildren():
      categories.append(cat.get_text())
  except AttributeError as e:
    return ', '.join(categories)
  
  categories = ', '.join(categories)
  return clean_text(categories)

def getOffer(bs):
  try:
    offer = bs.find('', {'class': 'specialOffer'}).get_text()
  except AttributeError as e:
    return ""
  return clean_text(offer)

def getDescription(bs):
  try:
    description = bs.find('', {'class': 'description'}).get_text()
  except AttributeError as e:
    return ""
  return clean_text(description)

def getServes(bs):
  try:
    Serves = bs.find('', {'class': 'detail-item'}).find('p').get_text()
  except AttributeError as e:
    return ""
  return clean_text(Serves)
    
def getKeywords(bs):
  try:
    Keywords = bs.find('', {'class': "detail-content-block"}).find('p').get_text()
  except AttributeError as e:
    return ""
  return clean_text(Keywords)

def get_company_infos(url):

  Infos = {}
  
  try:
    html = urlopen(url)
  except HTTPError as e:
    return None
  
  try:
    bsObj = BeautifulSoup(html.read(), "html.parser")
    
    Infos['name'] = getCompanyName(bsObj)
    Infos['mainphone'] = getCompanyMainPhone(bsObj)
    Infos['telephone'] = getCompanyPhone(bsObj)
    Infos['address'] = getAddress(bsObj)
    Infos['email'] = getEmail(bsObj)
    Infos['website'] = getWebsite(bsObj)
    Infos['fax'] = getFax(bsObj)
    Infos['about'] = getAbout(bsObj)
    Infos['categories'] = getCategories(bsObj)
    Infos['offer'] = getOffer(bsObj)
    Infos['description'] = getDescription(bsObj)
    Infos['Serves'] = getServes(bsObj)
    Infos['Keywords'] = getKeywords(bsObj)
    
  except AttributeError as e:
    return None
  
  return Infos

get_company_infos("https://www.goldenpages.ie/vhi-healthcare-dublin-D0177/")

import pandas as pd
from tqdm import tqdm

def getLinks(CompanyUrl):
  html = urlopen(CompanyUrl)
  bs = BeautifulSoup(html.read(), 'html.parser')
  
  return bs.find_all('a')

Alphabet = "ABCDEFGHIJKLMNOPQRSTUVWXYZ"
df = pd.DataFrame()

for a in Alphabet[0]:
  url = "https://www.goldenpages.ie/business/sitemap/" + a

  Links = getLinks(url)
  
  # Skip navigation Links
  Links = Links[len(Alphabet)+1:]
  
  for link in tqdm(Links):
    newCompany = "https://www.goldenpages.ie" + link.attrs['href']
    output = output.append(get_company_infos(newCompany), ignore_index=True)
    
df.head()

# Save CSV to Google Drive
from google.colab import drive
drive.mount('drive')

df.to_csv("goldenpages.csv")

!cp goldenpages.csv drive/My\ Drive/



